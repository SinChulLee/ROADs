{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48b2b08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import cv2\n",
    "import shutil\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from IPython import display\n",
    "from PIL import Image\n",
    "from ultralytics import YOLO\n",
    "from PIL import ImageFont, ImageDraw, Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "596ae64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('/Users/juhyeon/python-workspace/ROADs/best.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31cfd1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "label2id = {'etc': 0,\n",
    "            'PE드럼 정상': 1,\n",
    "            'PE드럼 파손': 2,\n",
    "            'PE방호벽 정상': 3,\n",
    "            'PE방호벽 파손': 4,\n",
    "            'PE안내봉 정상': 5,\n",
    "            'PE안내봉 파손': 6,\n",
    "            '라바콘 정상': 7,\n",
    "            '라바콘 파손': 8,\n",
    "            '시선유도봉 정상': 9,\n",
    "            '시선유도봉 파손': 10,\n",
    "            '제설함 정상': 11,\n",
    "            '제설함 파손': 12,\n",
    "            'PE입간판 정상': 13,\n",
    "            'PE입간판 파손': 14,\n",
    "            'PE휀스 정상': 15,\n",
    "            'PE휀스 파손': 16}\n",
    "\n",
    "# 반대로도 매핑할 수 있도록 딕셔너리 뒤집기!\n",
    "id2label = {v: k for k, v in label2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f38c772",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_largest_bbox(track_info_dict, id2label):\n",
    "    \"\"\"\n",
    "    각 bounding box의 넓이를 계산하고, 가장 큰 bbox를 찾는 함수\n",
    "    \"\"\"\n",
    "    max_area = 0\n",
    "    max_area_bbox = None\n",
    "    max_area_track_id = None\n",
    "    max_area_class_name = None\n",
    "\n",
    "    for track_id, track_info in track_info_dict.items():\n",
    "        class_id = track_info['cls_id']\n",
    "        class_name = id2label[class_id] if class_id in id2label else f'Unknown_{class_id}'\n",
    "\n",
    "        bbox = track_info['bbox'].int().tolist()\n",
    "        area = (bbox[2] - bbox[0]) * (bbox[3] - bbox[1])\n",
    "\n",
    "        if area > max_area:\n",
    "            max_area = area\n",
    "            max_area_bbox = bbox\n",
    "            max_area_track_id = track_id\n",
    "            max_area_class_name = class_name\n",
    "\n",
    "    return max_area_bbox, max_area_track_id, max_area_class_name\n",
    "\n",
    "def crop_and_save(frame, bbox, path):\n",
    "    \"\"\"\n",
    "    주어진 bbox를 프레임에서 잘라내고, 잘라낸 부분을 주어진 경로에 저장하는 함수\n",
    "    \"\"\"\n",
    "    cropped_frame = frame[bbox[1]:bbox[3], bbox[0]:bbox[2]]\n",
    "    cv2.imwrite(path, cropped_frame)\n",
    "    \n",
    "def is_overlapping(small_img_bbox, detected_bbox):\n",
    "    \"\"\"\n",
    "    크롭이미지와 이번에 검출된 이미지 사이에 겹치는 영역이 있는지 확인\n",
    "    \"\"\"\n",
    "    x_overlap = max(0, min(small_img_bbox[2], detected_bbox[2]) - max(small_img_bbox[0], detected_bbox[0]))\n",
    "    y_overlap = max(0, min(small_img_bbox[3], detected_bbox[3]) - max(small_img_bbox[1], detected_bbox[1]))\n",
    "    overlap_area = x_overlap * y_overlap\n",
    "    \n",
    "    return overlap_area > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933775c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_data(cursor, conn, s3_client, bucket_name, local_image_path, category_name):\n",
    "    response = requests.get('https://ipinfo.io')\n",
    "    data = response.json()\n",
    "    location = data.get('loc')\n",
    "    if location:\n",
    "        lat, long = location.split(',')\n",
    "    else:\n",
    "        print(\"위치 정보를 가져올 수 없습니다.\")\n",
    "\n",
    "    current_datetime = datetime.now()\n",
    "    s3_object_key = f'finalprojectimage/{os.path.basename(local_image_path)}'\n",
    "    s3_url = f'https://{bucket_name}.s3.ap-northeast-2.amazonaws.com/{s3_object_key}'\n",
    "\n",
    "    # 'gps_data' 테이블에 GPS 정보, 날짜, S3 경로, 카테고리 저장\n",
    "    query = 'INSERT INTO gps_data (latitude, longitude, datetime, img_path, category) VALUES (%s, %s, %s, %s, %s)'\n",
    "    values = (lat, long, current_datetime, s3_url, category_name)\n",
    "    \n",
    "    # s3에 이미지 업로드\n",
    "    s3_client.upload_file(local_image_path, bucket_name, s3_object_key)\n",
    "    print(f\"Image uploaded to S3: {s3_object_key}\")\n",
    "\n",
    "    cursor.execute(query, values)\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff75c33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from geopy.geocoders import Nominatim\n",
    "from decimal import Decimal\n",
    "from datetime import datetime\n",
    "import requests\n",
    "import boto3\n",
    "\n",
    "# AWS 계정 정보\n",
    "aws_access_key_id = \n",
    "aws_secret_access_key = \n",
    "aws_region = \n",
    "bucket_name = \n",
    "\n",
    "# AWS S3 클라이언트 생성\n",
    "s3_client = boto3.client('s3', \n",
    "                         aws_access_key_id=aws_access_key_id,\n",
    "                         aws_secret_access_key=aws_secret_access_key, \n",
    "                         region_name=aws_region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0585d438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/juhyeon/python-workspace/ROADs/test/frame_1.jpg\n",
      "트랙: {}\n",
      "current_frame_track_info: {1: {'bbox': tensor([1106.0850,  188.5902, 1250.5116,  264.6689]), 'cls_id': 14}}\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_2.jpg\n",
      "트랙: {1: {'latest_bbox_info': {'bbox': tensor([1106.0850,  188.5902, 1250.5116,  264.6689]), 'cls_id': 14}, 'frame_i': 0}}\n",
      "current_frame_track_info: {1: {'bbox': tensor([1110.3380,  190.9170, 1254.2474,  270.7471]), 'cls_id': 14}}\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_3.jpg\n",
      "트랙: {1: {'latest_bbox_info': {'bbox': tensor([1110.3380,  190.9170, 1254.2474,  270.7471]), 'cls_id': 14}, 'frame_i': 1}}\n",
      "current_frame_track_info: {1: {'bbox': tensor([1113.1306,  197.0028, 1258.3767,  277.9191]), 'cls_id': 14}}\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_4.jpg\n",
      "트랙: {1: {'latest_bbox_info': {'bbox': tensor([1113.1306,  197.0028, 1258.3767,  277.9191]), 'cls_id': 14}, 'frame_i': 2}}\n",
      "current_frame_track_info: {1: {'bbox': tensor([1117.9114,  201.6272, 1266.4486,  284.9177]), 'cls_id': 14}}\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_5.jpg\n",
      "트랙: {1: {'latest_bbox_info': {'bbox': tensor([1117.9114,  201.6272, 1266.4486,  284.9177]), 'cls_id': 14}, 'frame_i': 3}}\n",
      "current_frame_track_info: {1: {'bbox': tensor([1122.1205,  204.3181, 1275.1123,  288.2363]), 'cls_id': 14}}\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_6.jpg\n",
      "트랙: {1: {'latest_bbox_info': {'bbox': tensor([1122.1205,  204.3181, 1275.1123,  288.2363]), 'cls_id': 14}, 'frame_i': 4}}\n",
      "current_frame_track_info: {1: {'bbox': tensor([1125.9943,  207.2699, 1280.7542,  291.7240]), 'cls_id': 14}}\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_7.jpg\n",
      "트랙: {1: {'latest_bbox_info': {'bbox': tensor([1125.9943,  207.2699, 1280.7542,  291.7240]), 'cls_id': 14}, 'frame_i': 5}}\n",
      "current_frame_track_info: {1: {'bbox': tensor([1128.7109,  212.3558, 1288.0919,  299.7640]), 'cls_id': 14}}\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_8.jpg\n",
      "트랙: {1: {'latest_bbox_info': {'bbox': tensor([1128.7109,  212.3558, 1288.0919,  299.7640]), 'cls_id': 14}, 'frame_i': 6}}\n",
      "current_frame_track_info: {1: {'bbox': tensor([1132.1860,  213.8552, 1294.6182,  302.5667]), 'cls_id': 14}}\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_9.jpg\n",
      "트랙: {1: {'latest_bbox_info': {'bbox': tensor([1132.1860,  213.8552, 1294.6182,  302.5667]), 'cls_id': 14}, 'frame_i': 7}}\n",
      "current_frame_track_info: {1: {'bbox': tensor([1137.4359,  216.2283, 1301.8004,  305.3480]), 'cls_id': 14}}\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_10.jpg\n",
      "트랙: {1: {'latest_bbox_info': {'bbox': tensor([1137.4359,  216.2283, 1301.8004,  305.3480]), 'cls_id': 14}, 'frame_i': 8}}\n",
      "current_frame_track_info: {1: {'bbox': tensor([1140.2981,  217.0260, 1308.2052,  307.9590]), 'cls_id': 14}}\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_11.jpg\n",
      "트랙: {1: {'latest_bbox_info': {'bbox': tensor([1140.2981,  217.0260, 1308.2052,  307.9590]), 'cls_id': 14}, 'frame_i': 9}}\n",
      "current_frame_track_info: {1: {'bbox': tensor([1195.9824,  263.7496, 1396.5035,  372.5418]), 'cls_id': 14}}\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_12.jpg\n",
      "트랙: {1: {'latest_bbox_info': {'bbox': tensor([1195.9824,  263.7496, 1396.5035,  372.5418]), 'cls_id': 14}, 'frame_i': 10}}\n",
      "current_frame_track_info: {1: {'bbox': tensor([1208.3556,  275.2257, 1416.0829,  387.3422]), 'cls_id': 14}}\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_13.jpg\n",
      "트랙: {1: {'latest_bbox_info': {'bbox': tensor([1208.3556,  275.2257, 1416.0829,  387.3422]), 'cls_id': 14}, 'frame_i': 11}}\n",
      "current_frame_track_info: {1: {'bbox': tensor([1216.0721,  284.4428, 1431.3960,  400.3991]), 'cls_id': 14}}\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_14.jpg\n",
      "트랙: {1: {'latest_bbox_info': {'bbox': tensor([1216.0721,  284.4428, 1431.3960,  400.3991]), 'cls_id': 14}, 'frame_i': 12}}\n",
      "current_frame_track_info: {1: {'bbox': tensor([1224.0686,  296.2512, 1443.9213,  412.4956]), 'cls_id': 14}}\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_15.jpg\n",
      "트랙: {1: {'latest_bbox_info': {'bbox': tensor([1224.0686,  296.2512, 1443.9213,  412.4956]), 'cls_id': 14}, 'frame_i': 13}}\n",
      "current_frame_track_info: {1: {'bbox': tensor([1238.9427,  310.7591, 1468.1276,  433.0834]), 'cls_id': 14}}\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_16.jpg\n",
      "트랙: {1: {'latest_bbox_info': {'bbox': tensor([1238.9427,  310.7591, 1468.1276,  433.0834]), 'cls_id': 14}, 'frame_i': 14}}\n",
      "current_frame_track_info: {1: {'bbox': tensor([1251.4353,  319.6015, 1487.7502,  444.7058]), 'cls_id': 14}}\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_17.jpg\n",
      "트랙: {1: {'latest_bbox_info': {'bbox': tensor([1251.4353,  319.6015, 1487.7502,  444.7058]), 'cls_id': 14}, 'frame_i': 15}}\n",
      "current_frame_track_info: {1: {'bbox': tensor([1265.1404,  325.4637, 1507.1874,  454.0631]), 'cls_id': 14}, 3: {'bbox': tensor([864.4783,  51.6280, 981.1856, 117.7362]), 'cls_id': 14}}\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_18.jpg\n",
      "트랙: {1: {'latest_bbox_info': {'bbox': tensor([1265.1404,  325.4637, 1507.1874,  454.0631]), 'cls_id': 14}, 'frame_i': 16}, 3: {'latest_bbox_info': {'bbox': tensor([864.4783,  51.6280, 981.1856, 117.7362]), 'cls_id': 14}, 'frame_i': 16}}\n",
      "current_frame_track_info: {1: {'bbox': tensor([1283.9548,  333.9322, 1531.9492,  464.3549]), 'cls_id': 14}, 3: {'bbox': tensor([832.4882,  33.7127, 991.8142, 120.1590]), 'cls_id': 14}}\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_19.jpg\n",
      "트랙: {1: {'latest_bbox_info': {'bbox': tensor([1283.9548,  333.9322, 1531.9492,  464.3549]), 'cls_id': 14}, 'frame_i': 17}, 3: {'latest_bbox_info': {'bbox': tensor([832.4882,  33.7127, 991.8142, 120.1590]), 'cls_id': 14}, 'frame_i': 17}}\n",
      "current_frame_track_info: {1: {'bbox': tensor([1300.8188,  340.9595, 1556.0325,  476.9992]), 'cls_id': 14}, 3: {'bbox': tensor([ 817.6060,   21.4737, 1000.3932,  122.2814]), 'cls_id': 14}}\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_20.jpg\n",
      "트랙: {1: {'latest_bbox_info': {'bbox': tensor([1300.8188,  340.9595, 1556.0325,  476.9992]), 'cls_id': 14}, 'frame_i': 18}, 3: {'latest_bbox_info': {'bbox': tensor([ 817.6060,   21.4737, 1000.3932,  122.2814]), 'cls_id': 14}, 'frame_i': 18}}\n",
      "current_frame_track_info: {1: {'bbox': tensor([1309.4691,  348.2691, 1572.1663,  486.3949]), 'cls_id': 14}, 3: {'bbox': tensor([ 809.6078,   16.0265, 1000.7097,  123.3497]), 'cls_id': 14}}\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_21.jpg\n",
      "트랙: {1: {'latest_bbox_info': {'bbox': tensor([1309.4691,  348.2691, 1572.1663,  486.3949]), 'cls_id': 14}, 'frame_i': 19}, 3: {'latest_bbox_info': {'bbox': tensor([ 809.6078,   16.0265, 1000.7097,  123.3497]), 'cls_id': 14}, 'frame_i': 19}}\n",
      "current_frame_track_info: {1: {'bbox': tensor([1320.2179,  357.7032, 1590.5824,  503.0103]), 'cls_id': 14}, 3: {'bbox': tensor([ 807.6117,   26.5875, 1000.8948,  126.0640]), 'cls_id': 14}}\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_22.jpg\n",
      "트랙: {1: {'latest_bbox_info': {'bbox': tensor([1320.2179,  357.7032, 1590.5824,  503.0103]), 'cls_id': 14}, 'frame_i': 20}, 3: {'latest_bbox_info': {'bbox': tensor([ 809.6078,   16.0265, 1000.7097,  123.3497]), 'cls_id': 14}, 'frame_i': 19}}\n",
      "current_frame_track_info: {1: {'bbox': tensor([1332.5981,  369.6661, 1608.6224,  515.6422]), 'cls_id': 14}, 3: {'bbox': tensor([ 810.4323,   22.9505, 1002.5454,  130.1606]), 'cls_id': 14}}\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_23.jpg\n",
      "트랙: {1: {'latest_bbox_info': {'bbox': tensor([1332.5981,  369.6661, 1608.6224,  515.6422]), 'cls_id': 14}, 'frame_i': 21}, 3: {'latest_bbox_info': {'bbox': tensor([ 810.4323,   22.9505, 1002.5454,  130.1606]), 'cls_id': 14}, 'frame_i': 21}}\n",
      "current_frame_track_info: {1: {'bbox': tensor([1348.2201,  378.3018, 1629.8203,  528.0128]), 'cls_id': 14}, 3: {'bbox': tensor([ 817.3210,   17.4424, 1008.7485,  131.8664]), 'cls_id': 14}}\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_24.jpg\n",
      "트랙: {1: {'latest_bbox_info': {'bbox': tensor([1348.2201,  378.3018, 1629.8203,  528.0128]), 'cls_id': 14}, 'frame_i': 22}, 3: {'latest_bbox_info': {'bbox': tensor([ 817.3210,   17.4424, 1008.7485,  131.8664]), 'cls_id': 14}, 'frame_i': 22}}\n",
      "current_frame_track_info: {1: {'bbox': tensor([1362.7417,  387.7305, 1650.2206,  541.9352]), 'cls_id': 14}, 3: {'bbox': tensor([ 820.3032,   22.0943, 1012.8005,  134.7910]), 'cls_id': 14}}\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_25.jpg\n",
      "트랙: {1: {'latest_bbox_info': {'bbox': tensor([1362.7417,  387.7305, 1650.2206,  541.9352]), 'cls_id': 14}, 'frame_i': 23}, 3: {'latest_bbox_info': {'bbox': tensor([ 817.3210,   17.4424, 1008.7485,  131.8664]), 'cls_id': 14}, 'frame_i': 22}}\n",
      "current_frame_track_info: {1: {'bbox': tensor([1380.9260,  395.6469, 1674.3462,  555.3422]), 'cls_id': 14}, 3: {'bbox': tensor([ 825.2578,   42.1032, 1018.4309,  136.1021]), 'cls_id': 14}}\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_26.jpg\n",
      "트랙: {1: {'latest_bbox_info': {'bbox': tensor([1380.9260,  395.6469, 1674.3462,  555.3422]), 'cls_id': 14}, 'frame_i': 24}, 3: {'latest_bbox_info': {'bbox': tensor([ 817.3210,   17.4424, 1008.7485,  131.8664]), 'cls_id': 14}, 'frame_i': 22}}\n",
      "current_frame_track_info: {1: {'bbox': tensor([1399.9552,  402.6196, 1703.5332,  566.9565]), 'cls_id': 14}, 3: {'bbox': tensor([ 833.9500,   51.0483, 1028.1826,  136.2309]), 'cls_id': 14}}\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_27.jpg\n",
      "트랙: {1: {'latest_bbox_info': {'bbox': tensor([1399.9552,  402.6196, 1703.5332,  566.9565]), 'cls_id': 14}, 'frame_i': 25}, 3: {'latest_bbox_info': {'bbox': tensor([ 817.3210,   17.4424, 1008.7485,  131.8664]), 'cls_id': 14}, 'frame_i': 22}}\n",
      "current_frame_track_info: {1: {'bbox': tensor([1418.7968,  408.5402, 1732.2488,  578.9279]), 'cls_id': 14}, 3: {'bbox': tensor([ 885.5320,   56.4928, 1035.4746,  135.4586]), 'cls_id': 14}}\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_28.jpg\n",
      "트랙: {1: {'latest_bbox_info': {'bbox': tensor([1418.7968,  408.5402, 1732.2488,  578.9279]), 'cls_id': 14}, 'frame_i': 26}, 3: {'latest_bbox_info': {'bbox': tensor([ 817.3210,   17.4424, 1008.7485,  131.8664]), 'cls_id': 14}, 'frame_i': 22}}\n",
      "current_frame_track_info: {1: {'bbox': tensor([1437.6146,  417.8843, 1756.7424,  590.7635]), 'cls_id': 14}, 3: {'bbox': tensor([ 884.4005,   57.5706, 1040.7699,  136.2506]), 'cls_id': 14}}\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_29.jpg\n",
      "트랙: {1: {'latest_bbox_info': {'bbox': tensor([1437.6146,  417.8843, 1756.7424,  590.7635]), 'cls_id': 14}, 'frame_i': 27}, 3: {'latest_bbox_info': {'bbox': tensor([ 817.3210,   17.4424, 1008.7485,  131.8664]), 'cls_id': 14}, 'frame_i': 22}}\n",
      "current_frame_track_info: {1: {'bbox': tensor([1455.0891,  426.8690, 1781.5758,  605.0446]), 'cls_id': 14}, 3: {'bbox': tensor([ 867.0125,   44.0273, 1048.4535,  137.2986]), 'cls_id': 14}}\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_30.jpg\n",
      "트랙: {1: {'latest_bbox_info': {'bbox': tensor([1455.0891,  426.8690, 1781.5758,  605.0446]), 'cls_id': 14}, 'frame_i': 28}, 3: {'latest_bbox_info': {'bbox': tensor([ 817.3210,   17.4424, 1008.7485,  131.8664]), 'cls_id': 14}, 'frame_i': 22}}\n",
      "current_frame_track_info: {1: {'bbox': tensor([1475.8910,  435.7676, 1811.5897,  616.6325]), 'cls_id': 14}, 3: {'bbox': tensor([ 864.9437,   24.3362, 1057.1974,  136.6940]), 'cls_id': 14}}\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_31.jpg\n",
      "트랙: {1: {'latest_bbox_info': {'bbox': tensor([1475.8910,  435.7676, 1811.5897,  616.6325]), 'cls_id': 14}, 'frame_i': 29}, 3: {'latest_bbox_info': {'bbox': tensor([ 817.3210,   17.4424, 1008.7485,  131.8664]), 'cls_id': 14}, 'frame_i': 22}}\n",
      "current_frame_track_info: {1: {'bbox': tensor([1512.9037,  452.3242, 1862.4830,  644.1869]), 'cls_id': 14}, 3: {'bbox': tensor([ 871.2068,   36.3446, 1073.1423,  138.7106]), 'cls_id': 14}}\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_32.jpg\n",
      "트랙: {1: {'latest_bbox_info': {'bbox': tensor([1512.9037,  452.3242, 1862.4830,  644.1869]), 'cls_id': 14}, 'frame_i': 30}, 3: {'latest_bbox_info': {'bbox': tensor([ 817.3210,   17.4424, 1008.7485,  131.8664]), 'cls_id': 14}, 'frame_i': 22}}\n",
      "current_frame_track_info: {3: {'bbox': tensor([ 898.6296,   16.9272, 1122.8699,  148.7243]), 'cls_id': 14}}\n",
      "Saved: /Users/juhyeon/python-workspace/ROADs/test_output_frames/frame_30_track_1.jpg for Track ID: 1\n",
      "Image uploaded to S3: finalprojectimage/frame_30_track_1.jpg\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_33.jpg\n",
      "트랙: {3: {'latest_bbox_info': {'bbox': tensor([ 898.6296,   16.9272, 1122.8699,  148.7243]), 'cls_id': 14}, 'frame_i': 31}}\n",
      "current_frame_track_info: {3: {'bbox': tensor([ 902.7449,   21.0141, 1124.8320,  149.8627]), 'cls_id': 14}}\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_34.jpg\n",
      "트랙: {3: {'latest_bbox_info': {'bbox': tensor([ 898.6296,   16.9272, 1122.8699,  148.7243]), 'cls_id': 14}, 'frame_i': 31}}\n",
      "current_frame_track_info: {3: {'bbox': tensor([ 902.4848,   24.1716, 1126.3341,  151.5379]), 'cls_id': 14}}\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_35.jpg\n",
      "트랙: {3: {'latest_bbox_info': {'bbox': tensor([ 898.6296,   16.9272, 1122.8699,  148.7243]), 'cls_id': 14}, 'frame_i': 31}}\n",
      "current_frame_track_info: {3: {'bbox': tensor([ 907.9524,   18.7188, 1128.1626,  151.9860]), 'cls_id': 14}}\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_36.jpg\n",
      "트랙: {3: {'latest_bbox_info': {'bbox': tensor([ 898.6296,   16.9272, 1122.8699,  148.7243]), 'cls_id': 14}, 'frame_i': 31}}\n",
      "current_frame_track_info: {3: {'bbox': tensor([ 959.3757,   47.9503, 1133.0785,  154.6533]), 'cls_id': 14}}\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_37.jpg\n",
      "트랙: {3: {'latest_bbox_info': {'bbox': tensor([ 898.6296,   16.9272, 1122.8699,  148.7243]), 'cls_id': 14}, 'frame_i': 31}}\n",
      "current_frame_track_info: {3: {'bbox': tensor([ 981.2308,   61.2026, 1136.0109,  157.1901]), 'cls_id': 14}}\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_38.jpg\n",
      "트랙: {3: {'latest_bbox_info': {'bbox': tensor([ 898.6296,   16.9272, 1122.8699,  148.7243]), 'cls_id': 14}, 'frame_i': 31}}\n",
      "current_frame_track_info: {3: {'bbox': tensor([ 989.8494,   68.3415, 1139.5531,  158.1767]), 'cls_id': 14}}\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_39.jpg\n",
      "트랙: {3: {'latest_bbox_info': {'bbox': tensor([ 898.6296,   16.9272, 1122.8699,  148.7243]), 'cls_id': 14}, 'frame_i': 31}}\n",
      "current_frame_track_info: {3: {'bbox': tensor([ 997.3852,   73.6338, 1146.4888,  160.6668]), 'cls_id': 14}}\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_40.jpg\n",
      "트랙: {3: {'latest_bbox_info': {'bbox': tensor([ 898.6296,   16.9272, 1122.8699,  148.7243]), 'cls_id': 14}, 'frame_i': 31}}\n",
      "current_frame_track_info: {3: {'bbox': tensor([1005.5618,   75.5201, 1156.2595,  165.2898]), 'cls_id': 14}}\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_41.jpg\n",
      "트랙: {3: {'latest_bbox_info': {'bbox': tensor([ 898.6296,   16.9272, 1122.8699,  148.7243]), 'cls_id': 14}, 'frame_i': 31}}\n",
      "current_frame_track_info: {3: {'bbox': tensor([1012.3460,   77.4802, 1162.9149,  168.8696]), 'cls_id': 14}}\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_42.jpg\n",
      "트랙: {3: {'latest_bbox_info': {'bbox': tensor([ 898.6296,   16.9272, 1122.8699,  148.7243]), 'cls_id': 14}, 'frame_i': 31}}\n",
      "current_frame_track_info: {3: {'bbox': tensor([1010.4165,   77.9807, 1162.8344,  170.9453]), 'cls_id': 14}}\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_43.jpg\n",
      "트랙: {3: {'latest_bbox_info': {'bbox': tensor([ 898.6296,   16.9272, 1122.8699,  148.7243]), 'cls_id': 14}, 'frame_i': 31}}\n",
      "current_frame_track_info: {3: {'bbox': tensor([1010.5406,   80.1746, 1162.9292,  173.3950]), 'cls_id': 14}}\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_44.jpg\n",
      "트랙: {3: {'latest_bbox_info': {'bbox': tensor([ 898.6296,   16.9272, 1122.8699,  148.7243]), 'cls_id': 14}, 'frame_i': 31}}\n",
      "current_frame_track_info: {3: {'bbox': tensor([1011.8123,   81.0456, 1166.8988,  175.5567]), 'cls_id': 14}}\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_45.jpg\n",
      "트랙: {3: {'latest_bbox_info': {'bbox': tensor([ 898.6296,   16.9272, 1122.8699,  148.7243]), 'cls_id': 14}, 'frame_i': 31}}\n",
      "current_frame_track_info: {3: {'bbox': tensor([1017.3428,   83.5313, 1174.6239,  179.7608]), 'cls_id': 14}}\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_46.jpg\n",
      "트랙: {3: {'latest_bbox_info': {'bbox': tensor([ 898.6296,   16.9272, 1122.8699,  148.7243]), 'cls_id': 14}, 'frame_i': 31}}\n",
      "current_frame_track_info: {3: {'bbox': tensor([1020.0499,   84.9691, 1179.7220,  183.4446]), 'cls_id': 14}}\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_47.jpg\n",
      "트랙: {3: {'latest_bbox_info': {'bbox': tensor([ 898.6296,   16.9272, 1122.8699,  148.7243]), 'cls_id': 14}, 'frame_i': 31}}\n",
      "current_frame_track_info: {3: {'bbox': tensor([1028.4961,   87.1777, 1194.0592,  188.8645]), 'cls_id': 14}}\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_48.jpg\n",
      "트랙: {3: {'latest_bbox_info': {'bbox': tensor([ 898.6296,   16.9272, 1122.8699,  148.7243]), 'cls_id': 14}, 'frame_i': 31}}\n",
      "current_frame_track_info: {3: {'bbox': tensor([1032.3254,   87.4218, 1200.8068,  190.0164]), 'cls_id': 14}}\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_49.jpg\n",
      "트랙: {3: {'latest_bbox_info': {'bbox': tensor([ 898.6296,   16.9272, 1122.8699,  148.7243]), 'cls_id': 14}, 'frame_i': 31}}\n",
      "current_frame_track_info: {3: {'bbox': tensor([1034.5725,   88.7802, 1205.9023,  192.8488]), 'cls_id': 14}}\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_50.jpg\n",
      "트랙: {3: {'latest_bbox_info': {'bbox': tensor([ 898.6296,   16.9272, 1122.8699,  148.7243]), 'cls_id': 14}, 'frame_i': 31}}\n",
      "current_frame_track_info: {3: {'bbox': tensor([1033.5947,   90.1317, 1205.8127,  195.1962]), 'cls_id': 14}}\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_51.jpg\n",
      "트랙: {3: {'latest_bbox_info': {'bbox': tensor([ 898.6296,   16.9272, 1122.8699,  148.7243]), 'cls_id': 14}, 'frame_i': 31}}\n",
      "current_frame_track_info: {3: {'bbox': tensor([1035.9662,   90.8262, 1208.5452,  196.9624]), 'cls_id': 14}}\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_52.jpg\n",
      "트랙: {3: {'latest_bbox_info': {'bbox': tensor([ 898.6296,   16.9272, 1122.8699,  148.7243]), 'cls_id': 14}, 'frame_i': 31}}\n",
      "current_frame_track_info: {3: {'bbox': tensor([1038.3324,   94.5016, 1213.5514,  199.9914]), 'cls_id': 14}}\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_53.jpg\n",
      "트랙: {3: {'latest_bbox_info': {'bbox': tensor([ 898.6296,   16.9272, 1122.8699,  148.7243]), 'cls_id': 14}, 'frame_i': 31}}\n",
      "current_frame_track_info: {3: {'bbox': tensor([1042.7289,   95.8258, 1219.7433,  202.0125]), 'cls_id': 14}}\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_54.jpg\n",
      "트랙: {3: {'latest_bbox_info': {'bbox': tensor([ 898.6296,   16.9272, 1122.8699,  148.7243]), 'cls_id': 14}, 'frame_i': 31}}\n",
      "current_frame_track_info: {3: {'bbox': tensor([1047.3131,   98.4076, 1226.6193,  204.5682]), 'cls_id': 14}}\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_55.jpg\n",
      "트랙: {3: {'latest_bbox_info': {'bbox': tensor([ 898.6296,   16.9272, 1122.8699,  148.7243]), 'cls_id': 14}, 'frame_i': 31}}\n",
      "current_frame_track_info: {3: {'bbox': tensor([1051.5078,   99.9489, 1232.2322,  207.7318]), 'cls_id': 14}}\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_56.jpg\n",
      "트랙: {3: {'latest_bbox_info': {'bbox': tensor([ 898.6296,   16.9272, 1122.8699,  148.7243]), 'cls_id': 14}, 'frame_i': 31}}\n",
      "current_frame_track_info: {3: {'bbox': tensor([1052.6331,  101.4010, 1237.4727,  211.5847]), 'cls_id': 14}}\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_57.jpg\n",
      "트랙: {3: {'latest_bbox_info': {'bbox': tensor([ 898.6296,   16.9272, 1122.8699,  148.7243]), 'cls_id': 14}, 'frame_i': 31}}\n",
      "current_frame_track_info: {3: {'bbox': tensor([1054.1853,  103.8566, 1239.4939,  216.2691]), 'cls_id': 14}}\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_58.jpg\n",
      "트랙: {3: {'latest_bbox_info': {'bbox': tensor([ 898.6296,   16.9272, 1122.8699,  148.7243]), 'cls_id': 14}, 'frame_i': 31}}\n",
      "current_frame_track_info: {3: {'bbox': tensor([1057.7729,  104.6510, 1249.9907,  221.0691]), 'cls_id': 14}}\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_59.jpg\n",
      "트랙: {3: {'latest_bbox_info': {'bbox': tensor([ 898.6296,   16.9272, 1122.8699,  148.7243]), 'cls_id': 14}, 'frame_i': 31}}\n",
      "current_frame_track_info: {3: {'bbox': tensor([1062.5293,  106.8483, 1257.1454,  225.4488]), 'cls_id': 14}}\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_60.jpg\n",
      "트랙: {3: {'latest_bbox_info': {'bbox': tensor([ 898.6296,   16.9272, 1122.8699,  148.7243]), 'cls_id': 14}, 'frame_i': 31}}\n",
      "current_frame_track_info: {3: {'bbox': tensor([1063.9008,  107.3130, 1261.2388,  228.9686]), 'cls_id': 14}}\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_61.jpg\n",
      "트랙: {3: {'latest_bbox_info': {'bbox': tensor([ 898.6296,   16.9272, 1122.8699,  148.7243]), 'cls_id': 14}, 'frame_i': 31}}\n",
      "current_frame_track_info: {3: {'bbox': tensor([1066.8217,  107.7023, 1265.9414,  231.6989]), 'cls_id': 14}}\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_62.jpg\n",
      "트랙: {3: {'latest_bbox_info': {'bbox': tensor([ 898.6296,   16.9272, 1122.8699,  148.7243]), 'cls_id': 14}, 'frame_i': 31}}\n",
      "current_frame_track_info: {3: {'bbox': tensor([1070.9965,  110.0200, 1276.9249,  234.9245]), 'cls_id': 14}}\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_63.jpg\n",
      "트랙: {3: {'latest_bbox_info': {'bbox': tensor([ 898.6296,   16.9272, 1122.8699,  148.7243]), 'cls_id': 14}, 'frame_i': 31}}\n",
      "current_frame_track_info: {3: {'bbox': tensor([1075.4840,  112.6085, 1283.2179,  238.3540]), 'cls_id': 14}}\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_64.jpg\n",
      "트랙: {3: {'latest_bbox_info': {'bbox': tensor([ 898.6296,   16.9272, 1122.8699,  148.7243]), 'cls_id': 14}, 'frame_i': 31}}\n",
      "current_frame_track_info: {3: {'bbox': tensor([1078.3250,  116.5847, 1290.8550,  242.4204]), 'cls_id': 14}}\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_65.jpg\n",
      "트랙: {3: {'latest_bbox_info': {'bbox': tensor([ 898.6296,   16.9272, 1122.8699,  148.7243]), 'cls_id': 14}, 'frame_i': 31}}\n",
      "current_frame_track_info: {3: {'bbox': tensor([1086.7609,  119.1537, 1301.8257,  245.6645]), 'cls_id': 14}}\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_66.jpg\n",
      "트랙: {3: {'latest_bbox_info': {'bbox': tensor([ 898.6296,   16.9272, 1122.8699,  148.7243]), 'cls_id': 14}, 'frame_i': 31}}\n",
      "current_frame_track_info: {3: {'bbox': tensor([1090.6688,  123.0204, 1308.7604,  252.0550]), 'cls_id': 14}}\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_67.jpg\n",
      "트랙: {3: {'latest_bbox_info': {'bbox': tensor([ 898.6296,   16.9272, 1122.8699,  148.7243]), 'cls_id': 14}, 'frame_i': 31}}\n",
      "current_frame_track_info: {3: {'bbox': tensor([1096.9181,  124.7223, 1316.3630,  257.2232]), 'cls_id': 14}}\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_68.jpg\n",
      "트랙: {3: {'latest_bbox_info': {'bbox': tensor([ 898.6296,   16.9272, 1122.8699,  148.7243]), 'cls_id': 14}, 'frame_i': 31}}\n",
      "current_frame_track_info: {3: {'bbox': tensor([1100.3098,  127.4620, 1322.9110,  260.8449]), 'cls_id': 14}}\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_69.jpg\n",
      "트랙: {3: {'latest_bbox_info': {'bbox': tensor([1100.3098,  127.4620, 1322.9110,  260.8449]), 'cls_id': 14}, 'frame_i': 67}}\n",
      "current_frame_track_info: {3: {'bbox': tensor([1103.1366,  129.4717, 1328.0533,  265.2885]), 'cls_id': 14}}\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_70.jpg\n",
      "트랙: {3: {'latest_bbox_info': {'bbox': tensor([1103.1366,  129.4717, 1328.0533,  265.2885]), 'cls_id': 14}, 'frame_i': 68}}\n",
      "current_frame_track_info: {3: {'bbox': tensor([1109.0338,  132.7796, 1342.9580,  274.2809]), 'cls_id': 14}}\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_71.jpg\n",
      "트랙: {3: {'latest_bbox_info': {'bbox': tensor([1109.0338,  132.7796, 1342.9580,  274.2809]), 'cls_id': 14}, 'frame_i': 69}}\n",
      "current_frame_track_info: {3: {'bbox': tensor([1112.4027,  134.8896, 1350.8818,  280.0714]), 'cls_id': 14}}\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_72.jpg\n",
      "트랙: {3: {'latest_bbox_info': {'bbox': tensor([1112.4027,  134.8896, 1350.8818,  280.0714]), 'cls_id': 14}, 'frame_i': 70}}\n",
      "current_frame_track_info: {3: {'bbox': tensor([1116.8510,  136.7139, 1360.1080,  283.5872]), 'cls_id': 14}}\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_73.jpg\n",
      "트랙: {3: {'latest_bbox_info': {'bbox': tensor([1116.8510,  136.7139, 1360.1080,  283.5872]), 'cls_id': 14}, 'frame_i': 71}}\n",
      "current_frame_track_info: {3: {'bbox': tensor([1118.5111,  140.5303, 1364.9216,  289.3093]), 'cls_id': 14}}\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_74.jpg\n",
      "트랙: {3: {'latest_bbox_info': {'bbox': tensor([1118.5111,  140.5303, 1364.9216,  289.3093]), 'cls_id': 14}, 'frame_i': 72}}\n",
      "current_frame_track_info: {3: {'bbox': tensor([1125.1202,  146.7466, 1381.1859,  303.1218]), 'cls_id': 14}}\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_75.jpg\n",
      "트랙: {3: {'latest_bbox_info': {'bbox': tensor([1125.1202,  146.7466, 1381.1859,  303.1218]), 'cls_id': 14}, 'frame_i': 73}}\n",
      "current_frame_track_info: {3: {'bbox': tensor([1128.3384,  149.2641, 1390.2511,  310.0722]), 'cls_id': 14}}\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_76.jpg\n",
      "트랙: {3: {'latest_bbox_info': {'bbox': tensor([1128.3384,  149.2641, 1390.2511,  310.0722]), 'cls_id': 14}, 'frame_i': 74}}\n",
      "current_frame_track_info: {3: {'bbox': tensor([1134.7158,  153.3778, 1403.6128,  316.2804]), 'cls_id': 14}}\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_77.jpg\n",
      "트랙: {3: {'latest_bbox_info': {'bbox': tensor([1134.7158,  153.3778, 1403.6128,  316.2804]), 'cls_id': 14}, 'frame_i': 75}}\n",
      "current_frame_track_info: {3: {'bbox': tensor([1142.4678,  156.4568, 1414.8120,  322.3719]), 'cls_id': 14}}\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_78.jpg\n",
      "트랙: {3: {'latest_bbox_info': {'bbox': tensor([1142.4678,  156.4568, 1414.8120,  322.3719]), 'cls_id': 14}, 'frame_i': 76}}\n",
      "current_frame_track_info: {3: {'bbox': tensor([1150.1561,  160.2572, 1426.3324,  327.6384]), 'cls_id': 14}}\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_79.jpg\n",
      "트랙: {3: {'latest_bbox_info': {'bbox': tensor([1150.1561,  160.2572, 1426.3324,  327.6384]), 'cls_id': 14}, 'frame_i': 77}}\n",
      "current_frame_track_info: {3: {'bbox': tensor([1163.2855,  167.6797, 1447.2960,  343.2570]), 'cls_id': 14}}\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_80.jpg\n",
      "트랙: {3: {'latest_bbox_info': {'bbox': tensor([1163.2855,  167.6797, 1447.2960,  343.2570]), 'cls_id': 14}, 'frame_i': 78}}\n",
      "current_frame_track_info: {3: {'bbox': tensor([1178.2201,  182.4560, 1481.8080,  366.7064]), 'cls_id': 14}}\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_81.jpg\n",
      "트랙: {3: {'latest_bbox_info': {'bbox': tensor([1178.2201,  182.4560, 1481.8080,  366.7064]), 'cls_id': 14}, 'frame_i': 79}}\n",
      "current_frame_track_info: {3: {'bbox': tensor([1184.2443,  187.5927, 1494.3115,  376.8227]), 'cls_id': 14}}\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_82.jpg\n",
      "트랙: {3: {'latest_bbox_info': {'bbox': tensor([1184.2443,  187.5927, 1494.3115,  376.8227]), 'cls_id': 14}, 'frame_i': 80}}\n",
      "current_frame_track_info: {3: {'bbox': tensor([1187.6183,  192.6772, 1504.5551,  385.9022]), 'cls_id': 14}}\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_83.jpg\n",
      "트랙: {3: {'latest_bbox_info': {'bbox': tensor([1187.6183,  192.6772, 1504.5551,  385.9022]), 'cls_id': 14}, 'frame_i': 81}}\n",
      "current_frame_track_info: {3: {'bbox': tensor([1193.4882,  198.8561, 1515.8496,  394.6866]), 'cls_id': 14}}\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_84.jpg\n",
      "트랙: {3: {'latest_bbox_info': {'bbox': tensor([1193.4882,  198.8561, 1515.8496,  394.6866]), 'cls_id': 14}, 'frame_i': 82}}\n",
      "current_frame_track_info: {3: {'bbox': tensor([1199.6945,  204.6846, 1528.5493,  404.6064]), 'cls_id': 14}}\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_85.jpg\n",
      "트랙: {3: {'latest_bbox_info': {'bbox': tensor([1199.6945,  204.6846, 1528.5493,  404.6064]), 'cls_id': 14}, 'frame_i': 83}}\n",
      "current_frame_track_info: {3: {'bbox': tensor([1208.2753,  210.5284, 1542.5542,  414.1141]), 'cls_id': 14}}\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_86.jpg\n",
      "트랙: {3: {'latest_bbox_info': {'bbox': tensor([1208.2753,  210.5284, 1542.5542,  414.1141]), 'cls_id': 14}, 'frame_i': 84}}\n",
      "current_frame_track_info: {3: {'bbox': tensor([1214.6561,  215.6813, 1559.7114,  425.3745]), 'cls_id': 14}}\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_87.jpg\n",
      "트랙: {3: {'latest_bbox_info': {'bbox': tensor([1214.6561,  215.6813, 1559.7114,  425.3745]), 'cls_id': 14}, 'frame_i': 85}}\n",
      "current_frame_track_info: {3: {'bbox': tensor([1236.3313,  227.9511, 1594.3777,  448.0276]), 'cls_id': 14}}\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_88.jpg\n",
      "트랙: {3: {'latest_bbox_info': {'bbox': tensor([1236.3313,  227.9511, 1594.3777,  448.0276]), 'cls_id': 14}, 'frame_i': 86}}\n",
      "current_frame_track_info: {3: {'bbox': tensor([1241.9869,  234.1312, 1610.8563,  461.3079]), 'cls_id': 14}, 6: {'bbox': tensor([ 991.8221,   43.1007, 1135.7703,  132.0373]), 'cls_id': 14}}\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_89.jpg\n",
      "트랙: {3: {'latest_bbox_info': {'bbox': tensor([1241.9869,  234.1312, 1610.8563,  461.3079]), 'cls_id': 14}, 'frame_i': 87}, 6: {'latest_bbox_info': {'bbox': tensor([ 991.8221,   43.1007, 1135.7703,  132.0373]), 'cls_id': 14}, 'frame_i': 87}}\n",
      "current_frame_track_info: {3: {'bbox': tensor([1249.5190,  242.0802, 1626.1691,  473.8022]), 'cls_id': 14}, 6: {'bbox': tensor([ 993.2293,   47.0164, 1136.8910,  136.2401]), 'cls_id': 14}}\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_90.jpg\n",
      "트랙: {3: {'latest_bbox_info': {'bbox': tensor([1249.5190,  242.0802, 1626.1691,  473.8022]), 'cls_id': 14}, 'frame_i': 88}, 6: {'latest_bbox_info': {'bbox': tensor([ 993.2293,   47.0164, 1136.8910,  136.2401]), 'cls_id': 14}, 'frame_i': 88}}\n",
      "current_frame_track_info: {3: {'bbox': tensor([1262.4626,  255.4389, 1658.5110,  498.3951]), 'cls_id': 14}, 6: {'bbox': tensor([ 995.4983,   48.9978, 1143.8391,  140.2625]), 'cls_id': 14}}\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_91.jpg\n",
      "트랙: {3: {'latest_bbox_info': {'bbox': tensor([1262.4626,  255.4389, 1658.5110,  498.3951]), 'cls_id': 14}, 'frame_i': 89}, 6: {'latest_bbox_info': {'bbox': tensor([ 995.4983,   48.9978, 1143.8391,  140.2625]), 'cls_id': 14}, 'frame_i': 89}}\n",
      "current_frame_track_info: {3: {'bbox': tensor([1271.3591,  262.5736, 1673.4197,  512.4567]), 'cls_id': 14}, 6: {'bbox': tensor([ 995.5416,   50.1195, 1143.1937,  142.0236]), 'cls_id': 14}}\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_92.jpg\n",
      "트랙: {3: {'latest_bbox_info': {'bbox': tensor([1271.3591,  262.5736, 1673.4197,  512.4567]), 'cls_id': 14}, 'frame_i': 90}, 6: {'latest_bbox_info': {'bbox': tensor([ 995.5416,   50.1195, 1143.1937,  142.0236]), 'cls_id': 14}, 'frame_i': 90}}\n",
      "current_frame_track_info: {3: {'bbox': tensor([1279.1047,  271.8666, 1691.8054,  526.8990]), 'cls_id': 14}, 6: {'bbox': tensor([ 995.0526,   52.0894, 1141.8926,  144.2538]), 'cls_id': 14}}\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_93.jpg\n",
      "트랙: {3: {'latest_bbox_info': {'bbox': tensor([1279.1047,  271.8666, 1691.8054,  526.8990]), 'cls_id': 14}, 'frame_i': 91}, 6: {'latest_bbox_info': {'bbox': tensor([ 995.5416,   50.1195, 1143.1937,  142.0236]), 'cls_id': 14}, 'frame_i': 90}}\n",
      "current_frame_track_info: {3: {'bbox': tensor([1285.9718,  279.0643, 1706.8230,  541.5541]), 'cls_id': 14}, 6: {'bbox': tensor([ 993.0189,   52.8682, 1141.2664,  145.5571]), 'cls_id': 14}}\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_94.jpg\n",
      "트랙: {3: {'latest_bbox_info': {'bbox': tensor([1285.9718,  279.0643, 1706.8230,  541.5541]), 'cls_id': 14}, 'frame_i': 92}, 6: {'latest_bbox_info': {'bbox': tensor([ 993.0189,   52.8682, 1141.2664,  145.5571]), 'cls_id': 14}, 'frame_i': 92}}\n",
      "current_frame_track_info: {3: {'bbox': tensor([1294.8268,  287.9569, 1723.2484,  555.7526]), 'cls_id': 14}, 6: {'bbox': tensor([ 992.2187,   53.4657, 1142.3224,  146.2261]), 'cls_id': 14}}\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_95.jpg\n",
      "트랙: {3: {'latest_bbox_info': {'bbox': tensor([1294.8268,  287.9569, 1723.2484,  555.7526]), 'cls_id': 14}, 'frame_i': 93}, 6: {'latest_bbox_info': {'bbox': tensor([ 992.2187,   53.4657, 1142.3224,  146.2261]), 'cls_id': 14}, 'frame_i': 93}}\n",
      "current_frame_track_info: {3: {'bbox': tensor([1305.5765,  296.4052, 1749.5406,  570.0894]), 'cls_id': 14}, 6: {'bbox': tensor([ 996.3878,   54.1278, 1148.7249,  146.4005]), 'cls_id': 14}}\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_96.jpg\n",
      "트랙: {3: {'latest_bbox_info': {'bbox': tensor([1305.5765,  296.4052, 1749.5406,  570.0894]), 'cls_id': 14}, 'frame_i': 94}, 6: {'latest_bbox_info': {'bbox': tensor([ 996.3878,   54.1278, 1148.7249,  146.4005]), 'cls_id': 14}, 'frame_i': 94}}\n",
      "current_frame_track_info: {3: {'bbox': tensor([1317.1335,  305.5217, 1777.1959,  587.3548]), 'cls_id': 14}, 6: {'bbox': tensor([1002.7537,   55.7052, 1153.8698,  148.7194]), 'cls_id': 14}}\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_97.jpg\n",
      "트랙: {3: {'latest_bbox_info': {'bbox': tensor([1317.1335,  305.5217, 1777.1959,  587.3548]), 'cls_id': 14}, 'frame_i': 95}, 6: {'latest_bbox_info': {'bbox': tensor([ 996.3878,   54.1278, 1148.7249,  146.4005]), 'cls_id': 14}, 'frame_i': 94}}\n",
      "current_frame_track_info: {3: {'bbox': tensor([1332.2535,  312.8385, 1800.5541,  603.5444]), 'cls_id': 14}, 6: {'bbox': tensor([1007.0998,   55.9486, 1159.3392,  151.2141]), 'cls_id': 14}}\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_98.jpg\n",
      "트랙: {3: {'latest_bbox_info': {'bbox': tensor([1332.2535,  312.8385, 1800.5541,  603.5444]), 'cls_id': 14}, 'frame_i': 96}, 6: {'latest_bbox_info': {'bbox': tensor([1007.0998,   55.9486, 1159.3392,  151.2141]), 'cls_id': 14}, 'frame_i': 96}}\n",
      "current_frame_track_info: {3: {'bbox': tensor([1347.7877,  321.8417, 1827.9786,  620.9261]), 'cls_id': 14}, 6: {'bbox': tensor([1012.8183,   56.5172, 1166.0728,  152.5268]), 'cls_id': 14}}\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_99.jpg\n",
      "트랙: {3: {'latest_bbox_info': {'bbox': tensor([1347.7877,  321.8417, 1827.9786,  620.9261]), 'cls_id': 14}, 'frame_i': 97}, 6: {'latest_bbox_info': {'bbox': tensor([1012.8183,   56.5172, 1166.0728,  152.5268]), 'cls_id': 14}, 'frame_i': 97}}\n",
      "current_frame_track_info: {3: {'bbox': tensor([1365.3436,  335.0388, 1855.0414,  640.8715]), 'cls_id': 14}, 6: {'bbox': tensor([1018.2761,   59.0523, 1174.3267,  154.8695]), 'cls_id': 14}}\n",
      "/Users/juhyeon/python-workspace/ROADs/test/frame_100.jpg\n",
      "트랙: {3: {'latest_bbox_info': {'bbox': tensor([1365.3436,  335.0388, 1855.0414,  640.8715]), 'cls_id': 14}, 'frame_i': 98}, 6: {'latest_bbox_info': {'bbox': tensor([1018.2761,   59.0523, 1174.3267,  154.8695]), 'cls_id': 14}, 'frame_i': 98}}\n",
      "current_frame_track_info: {3: {'bbox': tensor([1382.0649,  345.1726, 1883.9497,  660.9731]), 'cls_id': 14}, 6: {'bbox': tensor([1024.1981,   59.4894, 1180.9250,  157.5346]), 'cls_id': 14}}\n",
      "Saved: /Users/juhyeon/python-workspace/ROADs/test_output_frames/frame_99_track_3.jpg for Track ID: 3\n",
      "Image uploaded to S3: finalprojectimage/frame_99_track_3.jpg\n",
      "Saved: /Users/juhyeon/python-workspace/ROADs/test_output_frames/frame_99_track_6.jpg for Track ID: 6\n",
      "Image uploaded to S3: finalprojectimage/frame_99_track_6.jpg\n"
     ]
    }
   ],
   "source": [
    "##### setting #####\n",
    "image_folder_path = '/Users/juhyeon/python-workspace/ROADs/test'\n",
    "output_folder_path = '/Users/juhyeon/python-workspace/ROADs/test_output_frames'\n",
    "\n",
    "test_paths = []\n",
    "for filename in sorted(os.listdir(image_folder_path), key=lambda x: int(x.split(\"_\")[1].split(\".\")[0])):\n",
    "    if filename.endswith(\".jpg\") and filename.startswith(\"frame_\"):\n",
    "        file_path = os.path.join(image_folder_path, filename)\n",
    "        test_paths.append(file_path)\n",
    "\n",
    "broken_categories = [2, 4, 6, 8, 10, 12, 14, 16]   # 파손만 검출해야함\n",
    "font = ImageFont.truetype('/Users/juhyeon/python-workspace/ROADs/NanumGothic.ttf', 30)\n",
    "\n",
    "tracks = {}\n",
    "current_frame_track_info= {}\n",
    "\n",
    "IMGSZ = 640\n",
    "prev_cropped_frame = None\n",
    "small_img_bbox = [50, 50, 450, 350]  # 좌측상단의 크롭된 이미지 위치와 크기를 표현하는 bbox\n",
    "####################\n",
    "\n",
    "##### PostgreSQL DB 연결 #####\n",
    "db_params = {'dbname': 'test',\n",
    "             'user': 'postgres',\n",
    "             'password': 'postgres',\n",
    "             'host': 'localhost',\n",
    "             'port': '5432'\n",
    "            }\n",
    "\n",
    "conn = psycopg2.connect(**db_params)\n",
    "cursor = conn.cursor()\n",
    "#############################\n",
    "\n",
    "#####   1. 이미지를 순차적으로 1~100 돌면서 검출 & 프레임당 가지고 있는 정보 가져오기(tracks에 저장됨)  #####\n",
    "for i, image_path in enumerate(test_paths):\n",
    "    frame = cv2.imread(image_path)\n",
    "    results = model.track(frame, persist=True, imgsz=IMGSZ, verbose=False)\n",
    "    # 트랙: {0: {'latest_bbox_info': {'bbox': tensor([550.9120, 516.0292, 591.8289, 719.9888]), 'cls_id': 0}}}\n",
    "    print(f'트랙: {tracks}')\n",
    "    \n",
    "    current_frame_track_info = {int(box[4].item()): {'bbox': box[:4], \n",
    "                                                 'cls_id': int(box[6].item()) if len(box) == 7 else int(box[5].item())} \n",
    "                            for box in results[0].boxes.data if int(box[6].item() if len(box) == 7 else box[5].item()) in broken_categories}\n",
    "    print(f'current_frame_track_info: {current_frame_track_info}')\n",
    "    \n",
    "#####   2. tracks{}에 저장된 각각의 track_id 별로 bbox 넓이 비교해서 제일 큰 것만 남도록 하는 과정   #####\n",
    "    \n",
    "    ######## [추가!!!] 각 프레임에서 가장 큰 bbox와 해당하는 트랙 ID, 클래스명 찾기\n",
    "    largest_bbox, largest_bbox_track_id, largest_bbox_class_name = find_largest_bbox(current_frame_track_info, id2label)\n",
    "    ##################################################################\n",
    "    \n",
    "    # 각 프레임에서 검출된 모든 객체의 bbox와 클래스명을 화면에 표시\n",
    "    for track_id, track_info in current_frame_track_info.items():\n",
    "        bbox = track_info['bbox'].int().tolist()\n",
    "        cls_id = track_info['cls_id']\n",
    "        category_name = id2label[cls_id] if cls_id in id2label else f'Unknown_{cls_id}'\n",
    "        \n",
    "        if track_id in tracks:\n",
    "            # 기존 정보가 없다면?\n",
    "            if 'latest_bbox_info' not in tracks[track_id]:\n",
    "                tracks[track_id]['latest_bbox_info'] = track_info\n",
    "                tracks[track_id]['frame_i'] = i\n",
    "                \n",
    "            # 기존 정보가 있다면 비교!\n",
    "            else:\n",
    "                current_bbox_size = (track_info['bbox'][2] - track_info['bbox'][0]) * (track_info['bbox'][3] - track_info['bbox'][1])\n",
    "                stored_bbox_size = (tracks[track_id]['latest_bbox_info']['bbox'][2] - tracks[track_id]['latest_bbox_info']['bbox'][0]) * \\\n",
    "                                   (tracks[track_id]['latest_bbox_info']['bbox'][3] - tracks[track_id]['latest_bbox_info']['bbox'][1])\n",
    "                \n",
    "                # 현재 bbox 넓이가 더 크면 원래 정보를 업데이트\n",
    "                #  track_info : {'bbox': tensor([174.2584, 524.3750, 223.3572, 684.6147]), 'cls_id': 0}\n",
    "                if current_bbox_size > stored_bbox_size:\n",
    "                    tracks[track_id]['latest_bbox_info'] = track_info\n",
    "                    tracks[track_id]['frame_i'] = i  # 가장 큰 bbox를 가진 프레임 정보 업데이트\n",
    "        else:\n",
    "            # 새로운 트랙 ID일 경우, 현재 프레임 정보 저장\n",
    "            tracks[track_id] = {'latest_bbox_info': track_info, 'frame_i': i}\n",
    "        ######################################################################\n",
    "        \n",
    "    ################################ [추가!!!]검출된 bbox들이 좌측상단의 이미지와 겹치는지 확인 ##########\n",
    "        if not is_overlapping(small_img_bbox, bbox):\n",
    "            # 겹치지 않으면 bbox를 그림\n",
    "            cv2.rectangle(frame, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (0, 255, 0), 3)\n",
    "            \n",
    "            ##### 한글처리 위해서 CV => PIL => CV 변환과정 진행 #####\n",
    "            frame_pil = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "            draw = ImageDraw.Draw(frame_pil)\n",
    "            draw.text((bbox[0], bbox[1] - 30), category_name, font=font, fill=(0, 255, 0))\n",
    "            \n",
    "            frame = cv2.cvtColor(np.array(frame_pil), cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "    # 좌측상단에 띄워주기 (선택된 bbox 잘라서!)\n",
    "    if largest_bbox is not None and label2id[largest_bbox_class_name] in broken_categories:\n",
    "        cropped_frame = frame[largest_bbox[1]:largest_bbox[3], largest_bbox[0]:largest_bbox[2]]\n",
    "        prev_cropped_frame = cropped_frame.copy()    \n",
    "        \n",
    "        # 이전 프레임의 cropped 부분을 현재 프레임의 좌측 상단에 붙이기\n",
    "        if prev_cropped_frame is not None:\n",
    "            # (가로, 세로)\n",
    "            resized_prev_cropped_frame = cv2.resize(prev_cropped_frame, (400, 300))\n",
    "            # 현재 프레임의 좌측 상단 부분에 이전 프레임의 cropped 부분 붙임 (세로, 가로)\n",
    "            frame[50:350, 50:450] = resized_prev_cropped_frame\n",
    "    ##########################################################################################\n",
    "\n",
    "    cv2.imshow('Frame', frame)\n",
    "    cv2.waitKey(1)  # 이미지를 1ms 동안 표시. 0을 입력하면 키 입력이 있을 때까지 이미지를 계속 표시\n",
    "\n",
    "    \n",
    "#####   3. 더 이상 다음 프레임에 해당 track_id가 검출되지 않는다면, tracks{}에 남아있는 bbox, fram_id 정보로 이미지 저장 #####\n",
    "\n",
    "    # 이전 프레임에서 트래킹했던 track_ID 중에서 현재 프레임에서는 검출되지 않은 track_id를 찾아냄\n",
    "    disappeared_track_ids = set(tracks.keys()) - set(current_frame_track_info.keys())\n",
    "    \n",
    "    # 더 이상 현재 프레임에서 검출되지 않는 track_id 에서 작업 수행\n",
    "    for disappeared_track_id in disappeared_track_ids:\n",
    "        try:\n",
    "            latest_bbox_info = tracks[disappeared_track_id]['latest_bbox_info']\n",
    "            output_path = os.path.join(output_folder_path, f'frame_{tracks[disappeared_track_id][\"frame_i\"]}_track_{disappeared_track_id}.jpg')\n",
    "            \n",
    "            # [xmin, ymin, xmax, ymax] 정수 coordinate\n",
    "            bbox = latest_bbox_info['bbox'].int().tolist()\n",
    "            \n",
    "            cls_id = latest_bbox_info['cls_id']\n",
    "            category_name = id2label[cls_id] if cls_id in id2label else f'Unknown_{cls_id}'\n",
    "            \n",
    "            # 가장 큰 bbox를 가진 프레임의 이미지를 다시 불러오기\n",
    "            img_path = test_paths[tracks[disappeared_track_id][\"frame_i\"]]\n",
    "            frame = cv2.imread(img_path)\n",
    "            \n",
    "            # (bbox[0], bbox[1]): 왼쪽 상단 좌표 (xmin, ymin)\n",
    "            # (bbox[2], bbox[3]): 오른쪽 하단 좌표 (xmax, ymax)\n",
    "            cv2.rectangle(frame, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (0, 255, 0), 3)\n",
    "            \n",
    "            # 한글처리 위해서 CV => PIL => CV 변환과정 진행\n",
    "            frame_pil = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "            draw = ImageDraw.Draw(frame_pil)\n",
    "            draw.text((bbox[0], bbox[1] - 30), category_name, font=font, fill=(0, 255, 0))\n",
    "            frame = cv2.cvtColor(np.array(frame_pil), cv2.COLOR_RGB2BGR)\n",
    "            cv2.imwrite(output_path, frame)\n",
    "\n",
    "            print(f'Saved: {output_path} for Track ID: {disappeared_track_id}')\n",
    "            \n",
    "            # DB/S3 으로 데이터(좌표,날짜,이미지,url)전송\n",
    "            transfer_data(cursor, conn, s3_client, bucket_name, output_path, category_name)\n",
    "\n",
    "            # 해당 트랙을 더 이상 추적하지 않도록 목록에서 제거\n",
    "            del tracks[disappeared_track_id]\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred for Track ID {disappeared_track_id} on frame {i}: {e}\")\n",
    "\n",
    "# 프레임 보여주던 창 닫기!\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "#####    4.  프레임이 모두 재생되었는데, 마지막 프레임에 끝까지 검출되는 것이 있다면?   #####\n",
    "# tracks{} 에서, 마지막까지 남은 track_id의 정보를 바탕으로 이미지 저장하고 끝냄\n",
    "for track_id in tracks.keys():\n",
    "    try:\n",
    "        latest_bbox_info = tracks[track_id]['latest_bbox_info']\n",
    "        output_path = os.path.join(output_folder_path, f'frame_{tracks[track_id][\"frame_i\"]}_track_{track_id}.jpg')\n",
    "        \n",
    "        bbox = latest_bbox_info['bbox'].int().tolist()\n",
    "        \n",
    "        cls_id = latest_bbox_info['cls_id']\n",
    "        category_name = id2label[cls_id] if cls_id in id2label else f'Unknown_{cls_id}'\n",
    "        \n",
    "        img_path = test_paths[tracks[track_id][\"frame_i\"]]\n",
    "        frame = cv2.imread(img_path)\n",
    "        \n",
    "        cv2.rectangle(frame, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (0, 255, 0), 3)\n",
    "        \n",
    "        ##### 한글처리 위해서 CV => PIL => CV 변환과정 진행 #####\n",
    "        frame_pil = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "        draw = ImageDraw.Draw(frame_pil)\n",
    "        draw.text((bbox[0], bbox[1] - 30), category_name, font=font, fill=(0, 255, 0))\n",
    "        frame = cv2.cvtColor(np.array(frame_pil), cv2.COLOR_RGB2BGR)\n",
    "        cv2.imwrite(output_path, frame)\n",
    "        print(f'Saved: {output_path} for Track ID: {track_id}')\n",
    "        \n",
    "        # DB/S3 으로 데이터(좌표,날짜,이미지,url)전송\n",
    "        transfer_data(cursor, conn, s3_client, bucket_name, output_path, category_name)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred for Track ID {track_id} on the final frame : {e}\")\n",
    "\n",
    "cursor.close()\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
