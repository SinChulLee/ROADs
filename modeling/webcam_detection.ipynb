{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6619668b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /Users/juhyeon/anaconda3/lib/python3.11/site-packages (23.3.2)\n",
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "Installed kernelspec yolov8 in /Users/juhyeon/Library/Jupyter/kernels/yolov8\n",
      "Collecting opencv-python==4.6.0.66\n",
      "  Downloading opencv_python-4.6.0.66-cp37-abi3-macosx_11_0_arm64.whl (30.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.0/30.0 MB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.21.2 in /Users/juhyeon/anaconda3/lib/python3.11/site-packages (from opencv-python==4.6.0.66) (1.24.3)\n",
      "Installing collected packages: opencv-python\n",
      "  Attempting uninstall: opencv-python\n",
      "    Found existing installation: opencv-python 4.8.1.78\n",
      "    Uninstalling opencv-python-4.8.1.78:\n",
      "      Successfully uninstalled opencv-python-4.8.1.78\n",
      "Successfully installed opencv-python-4.6.0.66\n",
      "Collecting opencv-contrib-python==4.6.0.66\n",
      "  Downloading opencv_contrib_python-4.6.0.66-cp37-abi3-macosx_11_0_arm64.whl (38.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.9/38.9 MB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.21.2 in /Users/juhyeon/anaconda3/lib/python3.11/site-packages (from opencv-contrib-python==4.6.0.66) (1.24.3)\n",
      "Installing collected packages: opencv-contrib-python\n",
      "Successfully installed opencv-contrib-python-4.6.0.66\n"
     ]
    }
   ],
   "source": [
    "!pip3 install --upgrade pip\n",
    "!python -m ipykernel install --user --name yolov8\n",
    "!pip3 install opencv-python==4.6.0.66\n",
    "!pip3 install opencv-contrib-python==4.6.0.66"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db218667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ultralytics\n",
      "  Downloading ultralytics-8.0.237-py3-none-any.whl.metadata (39 kB)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /Users/juhyeon/anaconda3/lib/python3.11/site-packages (from ultralytics) (3.7.2)\n",
      "Requirement already satisfied: numpy>=1.22.2 in /Users/juhyeon/anaconda3/lib/python3.11/site-packages (from ultralytics) (1.24.3)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /Users/juhyeon/anaconda3/lib/python3.11/site-packages (from ultralytics) (4.6.0.66)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /Users/juhyeon/anaconda3/lib/python3.11/site-packages (from ultralytics) (9.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /Users/juhyeon/anaconda3/lib/python3.11/site-packages (from ultralytics) (6.0)\n",
      "Requirement already satisfied: requests>=2.23.0 in /Users/juhyeon/anaconda3/lib/python3.11/site-packages (from ultralytics) (2.31.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /Users/juhyeon/anaconda3/lib/python3.11/site-packages (from ultralytics) (1.11.1)\n",
      "Requirement already satisfied: torch>=1.8.0 in /Users/juhyeon/anaconda3/lib/python3.11/site-packages (from ultralytics) (2.1.1)\n",
      "Collecting torchvision>=0.9.0 (from ultralytics)\n",
      "  Downloading torchvision-0.16.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /Users/juhyeon/anaconda3/lib/python3.11/site-packages (from ultralytics) (4.65.0)\n",
      "Requirement already satisfied: psutil in /Users/juhyeon/anaconda3/lib/python3.11/site-packages (from ultralytics) (5.9.0)\n",
      "Requirement already satisfied: py-cpuinfo in /Users/juhyeon/anaconda3/lib/python3.11/site-packages (from ultralytics) (8.0.0)\n",
      "Collecting thop>=0.1.1 (from ultralytics)\n",
      "  Using cached thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /Users/juhyeon/anaconda3/lib/python3.11/site-packages (from ultralytics) (2.0.3)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /Users/juhyeon/anaconda3/lib/python3.11/site-packages (from ultralytics) (0.12.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/juhyeon/anaconda3/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/juhyeon/anaconda3/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/juhyeon/anaconda3/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/juhyeon/anaconda3/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/juhyeon/anaconda3/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (23.1)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /Users/juhyeon/anaconda3/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/juhyeon/anaconda3/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/juhyeon/anaconda3/lib/python3.11/site-packages (from pandas>=1.1.4->ultralytics) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/juhyeon/anaconda3/lib/python3.11/site-packages (from pandas>=1.1.4->ultralytics) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/juhyeon/anaconda3/lib/python3.11/site-packages (from requests>=2.23.0->ultralytics) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/juhyeon/anaconda3/lib/python3.11/site-packages (from requests>=2.23.0->ultralytics) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/juhyeon/anaconda3/lib/python3.11/site-packages (from requests>=2.23.0->ultralytics) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/juhyeon/anaconda3/lib/python3.11/site-packages (from requests>=2.23.0->ultralytics) (2023.7.22)\n",
      "Requirement already satisfied: filelock in /Users/juhyeon/anaconda3/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /Users/juhyeon/anaconda3/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (4.7.1)\n",
      "Requirement already satisfied: sympy in /Users/juhyeon/anaconda3/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (1.11.1)\n",
      "Requirement already satisfied: networkx in /Users/juhyeon/anaconda3/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/juhyeon/anaconda3/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /Users/juhyeon/anaconda3/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (2023.4.0)\n",
      "Collecting torch>=1.8.0 (from ultralytics)\n",
      "  Downloading torch-2.1.2-cp311-none-macosx_11_0_arm64.whl.metadata (25 kB)\n",
      "Requirement already satisfied: six>=1.5 in /Users/juhyeon/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/juhyeon/anaconda3/lib/python3.11/site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/juhyeon/anaconda3/lib/python3.11/site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Downloading ultralytics-8.0.237-py3-none-any.whl (691 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m691.9/691.9 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading torchvision-0.16.2-cp311-cp311-macosx_11_0_arm64.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.1.2-cp311-none-macosx_11_0_arm64.whl (59.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.6/59.6 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torch, torchvision, thop, ultralytics\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.1.1\n",
      "    Uninstalling torch-2.1.1:\n",
      "      Successfully uninstalled torch-2.1.1\n",
      "Successfully installed thop-0.1.1.post2209072238 torch-2.1.2 torchvision-0.16.2 ultralytics-8.0.237\n",
      "Collecting deep-sort-realtime\n",
      "  Downloading deep_sort_realtime-1.3.2-py3-none-any.whl (8.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /Users/juhyeon/anaconda3/lib/python3.11/site-packages (from deep-sort-realtime) (1.24.3)\n",
      "Requirement already satisfied: scipy in /Users/juhyeon/anaconda3/lib/python3.11/site-packages (from deep-sort-realtime) (1.11.1)\n",
      "Requirement already satisfied: opencv-python in /Users/juhyeon/anaconda3/lib/python3.11/site-packages (from deep-sort-realtime) (4.6.0.66)\n",
      "Installing collected packages: deep-sort-realtime\n",
      "Successfully installed deep-sort-realtime-1.3.2\n"
     ]
    }
   ],
   "source": [
    "!pip3 install ultralytics\n",
    "!pip3 install deep-sort-realtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5882ae7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import cv2\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b31fc88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIDENCE_THRESHOLD = 0.6\n",
    "GREEN = (0, 255, 0)\n",
    "WHITE = (255, 255, 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3974ca35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coco dataset (80 object categories)\n",
    "class_list = [\n",
    "    'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck',\n",
    "    'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench',\n",
    "    'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe',\n",
    "    'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard',\n",
    "    'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard',\n",
    "    'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl',\n",
    "    'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
    "    'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet',\n",
    "    'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven',\n",
    "    'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear',\n",
    "    'hair drier', 'toothbrush'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5518bbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('./yolov8_pretrained/yolov8n.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "caf261da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8s.pt to 'yolov8_pretrained/yolov8s.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 21.5M/21.5M [00:02<00:00, 11.2MB/s]\n"
     ]
    }
   ],
   "source": [
    "model = YOLO('./yolov8_pretrained/yolov8s.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82fd1255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a703a92c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 person, 116.8ms\n",
      "Speed: 2.3ms preprocess, 116.8ms inference, 7.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 961 milliseconds\n",
      "FPS: 1.04\n",
      "\n",
      "0: 480x640 1 person, 99.2ms\n",
      "Speed: 1.0ms preprocess, 99.2ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 123 milliseconds\n",
      "FPS: 8.13\n",
      "\n",
      "0: 480x640 1 person, 101.1ms\n",
      "Speed: 1.0ms preprocess, 101.1ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 122 milliseconds\n",
      "FPS: 8.19\n",
      "\n",
      "0: 480x640 1 person, 151.4ms\n",
      "Speed: 1.7ms preprocess, 151.4ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 210 milliseconds\n",
      "FPS: 4.76\n",
      "\n",
      "0: 480x640 1 person, 106.8ms\n",
      "Speed: 1.2ms preprocess, 106.8ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 114 milliseconds\n",
      "FPS: 8.80\n",
      "\n",
      "0: 480x640 1 person, 103.4ms\n",
      "Speed: 1.0ms preprocess, 103.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 116 milliseconds\n",
      "FPS: 8.62\n",
      "\n",
      "0: 480x640 1 person, 100.9ms\n",
      "Speed: 1.3ms preprocess, 100.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 119 milliseconds\n",
      "FPS: 8.42\n",
      "\n",
      "0: 480x640 1 person, 103.0ms\n",
      "Speed: 0.8ms preprocess, 103.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 122 milliseconds\n",
      "FPS: 8.17\n",
      "\n",
      "0: 480x640 1 person, 154.8ms\n",
      "Speed: 0.8ms preprocess, 154.8ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 172 milliseconds\n",
      "FPS: 5.80\n",
      "\n",
      "0: 480x640 1 person, 102.3ms\n",
      "Speed: 1.1ms preprocess, 102.3ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 136 milliseconds\n",
      "FPS: 7.36\n",
      "\n",
      "0: 480x640 1 person, 105.2ms\n",
      "Speed: 1.2ms preprocess, 105.2ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 124 milliseconds\n",
      "FPS: 8.03\n",
      "\n",
      "0: 480x640 1 person, 121.0ms\n",
      "Speed: 1.0ms preprocess, 121.0ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 136 milliseconds\n",
      "FPS: 7.33\n",
      "\n",
      "0: 480x640 1 person, 101.0ms\n",
      "Speed: 1.1ms preprocess, 101.0ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 134 milliseconds\n",
      "FPS: 7.48\n",
      "\n",
      "0: 480x640 1 person, 100.1ms\n",
      "Speed: 1.0ms preprocess, 100.1ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 120 milliseconds\n",
      "FPS: 8.36\n",
      "\n",
      "0: 480x640 1 person, 103.6ms\n",
      "Speed: 1.1ms preprocess, 103.6ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 139 milliseconds\n",
      "FPS: 7.17\n",
      "\n",
      "0: 480x640 1 person, 101.3ms\n",
      "Speed: 1.0ms preprocess, 101.3ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 138 milliseconds\n",
      "FPS: 7.24\n",
      "\n",
      "0: 480x640 1 person, 100.0ms\n",
      "Speed: 1.3ms preprocess, 100.0ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 120 milliseconds\n",
      "FPS: 8.33\n",
      "\n",
      "0: 480x640 1 person, 101.6ms\n",
      "Speed: 1.1ms preprocess, 101.6ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 135 milliseconds\n",
      "FPS: 7.39\n",
      "\n",
      "0: 480x640 1 person, 106.6ms\n",
      "Speed: 1.2ms preprocess, 106.6ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 121 milliseconds\n",
      "FPS: 8.25\n",
      "\n",
      "0: 480x640 1 person, 101.4ms\n",
      "Speed: 1.5ms preprocess, 101.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 115 milliseconds\n",
      "FPS: 8.69\n",
      "\n",
      "0: 480x640 1 person, 1 banana, 98.8ms\n",
      "Speed: 1.2ms preprocess, 98.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 117 milliseconds\n",
      "FPS: 8.53\n",
      "\n",
      "0: 480x640 1 person, 104.8ms\n",
      "Speed: 0.9ms preprocess, 104.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 127 milliseconds\n",
      "FPS: 7.87\n",
      "\n",
      "0: 480x640 2 persons, 101.5ms\n",
      "Speed: 0.9ms preprocess, 101.5ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 118 milliseconds\n",
      "FPS: 8.50\n",
      "\n",
      "0: 480x640 2 persons, 1 donut, 100.0ms\n",
      "Speed: 1.2ms preprocess, 100.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 119 milliseconds\n",
      "FPS: 8.41\n",
      "\n",
      "0: 480x640 2 persons, 98.5ms\n",
      "Speed: 1.3ms preprocess, 98.5ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 119 milliseconds\n",
      "FPS: 8.39\n",
      "\n",
      "0: 480x640 2 persons, 99.3ms\n",
      "Speed: 0.9ms preprocess, 99.3ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 122 milliseconds\n",
      "FPS: 8.23\n",
      "\n",
      "0: 480x640 2 persons, 102.0ms\n",
      "Speed: 1.3ms preprocess, 102.0ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 125 milliseconds\n",
      "FPS: 8.03\n",
      "\n",
      "0: 480x640 1 person, 100.6ms\n",
      "Speed: 1.1ms preprocess, 100.6ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 118 milliseconds\n",
      "FPS: 8.45\n",
      "\n",
      "0: 480x640 1 person, 102.2ms\n",
      "Speed: 1.0ms preprocess, 102.2ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 122 milliseconds\n",
      "FPS: 8.18\n",
      "\n",
      "0: 480x640 1 person, 100.6ms\n",
      "Speed: 1.1ms preprocess, 100.6ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 120 milliseconds\n",
      "FPS: 8.33\n",
      "\n",
      "0: 480x640 1 person, 100.6ms\n",
      "Speed: 0.9ms preprocess, 100.6ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 121 milliseconds\n",
      "FPS: 8.30\n",
      "\n",
      "0: 480x640 1 person, 102.0ms\n",
      "Speed: 1.1ms preprocess, 102.0ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 122 milliseconds\n",
      "FPS: 8.20\n",
      "\n",
      "0: 480x640 1 person, 99.5ms\n",
      "Speed: 1.0ms preprocess, 99.5ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 119 milliseconds\n",
      "FPS: 8.40\n",
      "\n",
      "0: 480x640 1 person, 101.5ms\n",
      "Speed: 1.1ms preprocess, 101.5ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 122 milliseconds\n",
      "FPS: 8.17\n",
      "\n",
      "0: 480x640 1 person, 101.5ms\n",
      "Speed: 1.2ms preprocess, 101.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 121 milliseconds\n",
      "FPS: 8.26\n",
      "\n",
      "0: 480x640 1 person, 101.2ms\n",
      "Speed: 1.0ms preprocess, 101.2ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 120 milliseconds\n",
      "FPS: 8.36\n",
      "\n",
      "0: 480x640 1 person, 104.8ms\n",
      "Speed: 1.9ms preprocess, 104.8ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 125 milliseconds\n",
      "FPS: 8.00\n",
      "\n",
      "0: 480x640 1 person, 104.8ms\n",
      "Speed: 1.1ms preprocess, 104.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 121 milliseconds\n",
      "FPS: 8.29\n",
      "\n",
      "0: 480x640 1 person, 100.3ms\n",
      "Speed: 0.9ms preprocess, 100.3ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 118 milliseconds\n",
      "FPS: 8.45\n",
      "\n",
      "0: 480x640 1 person, 101.2ms\n",
      "Speed: 1.2ms preprocess, 101.2ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 120 milliseconds\n",
      "FPS: 8.34\n",
      "\n",
      "0: 480x640 1 person, 101.5ms\n",
      "Speed: 1.1ms preprocess, 101.5ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 120 milliseconds\n",
      "FPS: 8.31\n",
      "\n",
      "0: 480x640 1 person, 1 tie, 102.1ms\n",
      "Speed: 1.3ms preprocess, 102.1ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 123 milliseconds\n",
      "FPS: 8.13\n",
      "\n",
      "0: 480x640 1 person, 100.7ms\n",
      "Speed: 1.1ms preprocess, 100.7ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 119 milliseconds\n",
      "FPS: 8.43\n",
      "\n",
      "0: 480x640 1 person, 101.3ms\n",
      "Speed: 1.0ms preprocess, 101.3ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 122 milliseconds\n",
      "FPS: 8.20\n",
      "\n",
      "0: 480x640 1 person, 101.3ms\n",
      "Speed: 1.0ms preprocess, 101.3ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 121 milliseconds\n",
      "FPS: 8.26\n",
      "\n",
      "0: 480x640 1 person, 104.2ms\n",
      "Speed: 1.0ms preprocess, 104.2ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 123 milliseconds\n",
      "FPS: 8.12\n",
      "\n",
      "0: 480x640 1 person, 100.4ms\n",
      "Speed: 0.9ms preprocess, 100.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 117 milliseconds\n",
      "FPS: 8.51\n",
      "\n",
      "0: 480x640 1 person, 99.9ms\n",
      "Speed: 0.9ms preprocess, 99.9ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 120 milliseconds\n",
      "FPS: 8.33\n",
      "\n",
      "0: 480x640 1 person, 101.0ms\n",
      "Speed: 1.3ms preprocess, 101.0ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 122 milliseconds\n",
      "FPS: 8.18\n",
      "\n",
      "0: 480x640 1 person, 100.5ms\n",
      "Speed: 1.1ms preprocess, 100.5ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 120 milliseconds\n",
      "FPS: 8.30\n",
      "\n",
      "0: 480x640 1 person, 101.4ms\n",
      "Speed: 1.0ms preprocess, 101.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 121 milliseconds\n",
      "FPS: 8.25\n",
      "\n",
      "0: 480x640 1 person, 99.2ms\n",
      "Speed: 1.2ms preprocess, 99.2ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 118 milliseconds\n",
      "FPS: 8.50\n",
      "\n",
      "0: 480x640 1 person, 101.8ms\n",
      "Speed: 1.1ms preprocess, 101.8ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 125 milliseconds\n",
      "FPS: 8.02\n",
      "\n",
      "0: 480x640 1 person, 100.8ms\n",
      "Speed: 1.0ms preprocess, 100.8ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 119 milliseconds\n",
      "FPS: 8.38\n",
      "\n",
      "0: 480x640 1 person, 99.8ms\n",
      "Speed: 1.2ms preprocess, 99.8ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 121 milliseconds\n",
      "FPS: 8.29\n",
      "\n",
      "0: 480x640 1 person, 101.0ms\n",
      "Speed: 1.0ms preprocess, 101.0ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 122 milliseconds\n",
      "FPS: 8.22\n",
      "\n",
      "0: 480x640 1 person, 99.8ms\n",
      "Speed: 1.0ms preprocess, 99.8ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 120 milliseconds\n",
      "FPS: 8.37\n",
      "\n",
      "0: 480x640 1 person, 100.1ms\n",
      "Speed: 1.3ms preprocess, 100.1ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 122 milliseconds\n",
      "FPS: 8.17\n",
      "\n",
      "0: 480x640 1 person, 101.1ms\n",
      "Speed: 1.0ms preprocess, 101.1ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 121 milliseconds\n",
      "FPS: 8.23\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 100.1ms\n",
      "Speed: 1.0ms preprocess, 100.1ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 119 milliseconds\n",
      "FPS: 8.38\n",
      "\n",
      "0: 480x640 1 person, 100.3ms\n",
      "Speed: 1.0ms preprocess, 100.3ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 120 milliseconds\n",
      "FPS: 8.33\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 102.1ms\n",
      "Speed: 1.0ms preprocess, 102.1ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 123 milliseconds\n",
      "FPS: 8.11\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 101.8ms\n",
      "Speed: 1.3ms preprocess, 101.8ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 123 milliseconds\n",
      "FPS: 8.14\n",
      "\n",
      "0: 480x640 1 person, 2 cell phones, 99.4ms\n",
      "Speed: 0.9ms preprocess, 99.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 116 milliseconds\n",
      "FPS: 8.62\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 100.3ms\n",
      "Speed: 1.0ms preprocess, 100.3ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 122 milliseconds\n",
      "FPS: 8.17\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 101.7ms\n",
      "Speed: 0.9ms preprocess, 101.7ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 123 milliseconds\n",
      "FPS: 8.16\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 101.2ms\n",
      "Speed: 1.0ms preprocess, 101.2ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 120 milliseconds\n",
      "FPS: 8.31\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 102.9ms\n",
      "Speed: 1.3ms preprocess, 102.9ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 123 milliseconds\n",
      "FPS: 8.13\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 101.6ms\n",
      "Speed: 1.0ms preprocess, 101.6ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 119 milliseconds\n",
      "FPS: 8.39\n",
      "\n",
      "0: 480x640 1 person, 101.9ms\n",
      "Speed: 1.0ms preprocess, 101.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 121 milliseconds\n",
      "FPS: 8.27\n",
      "\n",
      "0: 480x640 1 person, 2 cell phones, 116.5ms\n",
      "Speed: 1.2ms preprocess, 116.5ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 139 milliseconds\n",
      "FPS: 7.19\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 109.0ms\n",
      "Speed: 1.2ms preprocess, 109.0ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 141 milliseconds\n",
      "FPS: 7.08\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 100.7ms\n",
      "Speed: 1.1ms preprocess, 100.7ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 114 milliseconds\n",
      "FPS: 8.77\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 99.9ms\n",
      "Speed: 1.0ms preprocess, 99.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 120 milliseconds\n",
      "FPS: 8.36\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 100.5ms\n",
      "Speed: 1.1ms preprocess, 100.5ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 121 milliseconds\n",
      "FPS: 8.26\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 100.2ms\n",
      "Speed: 1.2ms preprocess, 100.2ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 121 milliseconds\n",
      "FPS: 8.28\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 101.2ms\n",
      "Speed: 1.1ms preprocess, 101.2ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 122 milliseconds\n",
      "FPS: 8.18\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 99.4ms\n",
      "Speed: 1.0ms preprocess, 99.4ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 120 milliseconds\n",
      "FPS: 8.36\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 100.1ms\n",
      "Speed: 1.2ms preprocess, 100.1ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 120 milliseconds\n",
      "FPS: 8.31\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 101.0ms\n",
      "Speed: 1.0ms preprocess, 101.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 122 milliseconds\n",
      "FPS: 8.20\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 101.5ms\n",
      "Speed: 1.0ms preprocess, 101.5ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 121 milliseconds\n",
      "FPS: 8.25\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 100.8ms\n",
      "Speed: 1.0ms preprocess, 100.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 120 milliseconds\n",
      "FPS: 8.31\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 100.8ms\n",
      "Speed: 1.3ms preprocess, 100.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 122 milliseconds\n",
      "FPS: 8.21\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 99.3ms\n",
      "Speed: 0.9ms preprocess, 99.3ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 118 milliseconds\n",
      "FPS: 8.45\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 101.2ms\n",
      "Speed: 1.0ms preprocess, 101.2ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 123 milliseconds\n",
      "FPS: 8.12\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 99.6ms\n",
      "Speed: 1.0ms preprocess, 99.6ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 120 milliseconds\n",
      "FPS: 8.34\n",
      "\n",
      "0: 480x640 1 person, 2 cell phones, 100.4ms\n",
      "Speed: 1.1ms preprocess, 100.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 121 milliseconds\n",
      "FPS: 8.26\n",
      "\n",
      "0: 480x640 1 person, 99.5ms\n",
      "Speed: 1.0ms preprocess, 99.5ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 119 milliseconds\n",
      "FPS: 8.38\n",
      "\n",
      "0: 480x640 1 person, 99.7ms\n",
      "Speed: 1.0ms preprocess, 99.7ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 121 milliseconds\n",
      "FPS: 8.23\n",
      "\n",
      "0: 480x640 1 person, 100.7ms\n",
      "Speed: 1.0ms preprocess, 100.7ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 122 milliseconds\n",
      "FPS: 8.18\n",
      "\n",
      "0: 480x640 1 person, 99.9ms\n",
      "Speed: 1.3ms preprocess, 99.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 120 milliseconds\n",
      "FPS: 8.37\n",
      "\n",
      "0: 480x640 1 person, 100.4ms\n",
      "Speed: 1.1ms preprocess, 100.4ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 121 milliseconds\n",
      "FPS: 8.26\n",
      "\n",
      "0: 480x640 1 person, 99.8ms\n",
      "Speed: 0.9ms preprocess, 99.8ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 122 milliseconds\n",
      "FPS: 8.23\n",
      "\n",
      "0: 480x640 1 person, 99.6ms\n",
      "Speed: 1.2ms preprocess, 99.6ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 120 milliseconds\n",
      "FPS: 8.32\n",
      "\n",
      "0: 480x640 1 person, 100.4ms\n",
      "Speed: 0.9ms preprocess, 100.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 120 milliseconds\n",
      "FPS: 8.31\n",
      "\n",
      "0: 480x640 1 person, 98.3ms\n",
      "Speed: 1.2ms preprocess, 98.3ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 119 milliseconds\n",
      "FPS: 8.39\n",
      "\n",
      "0: 480x640 1 person, 102.5ms\n",
      "Speed: 1.0ms preprocess, 102.5ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 125 milliseconds\n",
      "FPS: 7.99\n",
      "\n",
      "0: 480x640 1 person, 102.2ms\n",
      "Speed: 1.0ms preprocess, 102.2ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 121 milliseconds\n",
      "FPS: 8.26\n",
      "\n",
      "0: 480x640 1 person, 98.6ms\n",
      "Speed: 1.0ms preprocess, 98.6ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 117 milliseconds\n",
      "FPS: 8.52\n",
      "\n",
      "0: 480x640 1 person, 100.8ms\n",
      "Speed: 0.9ms preprocess, 100.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 121 milliseconds\n",
      "FPS: 8.24\n",
      "\n",
      "0: 480x640 1 person, 100.2ms\n",
      "Speed: 1.0ms preprocess, 100.2ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 121 milliseconds\n",
      "FPS: 8.30\n",
      "\n",
      "0: 480x640 1 person, 100.2ms\n",
      "Speed: 1.0ms preprocess, 100.2ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 119 milliseconds\n",
      "FPS: 8.38\n",
      "\n",
      "0: 480x640 1 person, 99.8ms\n",
      "Speed: 1.0ms preprocess, 99.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 121 milliseconds\n",
      "FPS: 8.25\n",
      "\n",
      "0: 480x640 1 person, 102.0ms\n",
      "Speed: 1.0ms preprocess, 102.0ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 124 milliseconds\n",
      "FPS: 8.04\n",
      "\n",
      "0: 480x640 1 person, 104.1ms\n",
      "Speed: 1.0ms preprocess, 104.1ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 121 milliseconds\n",
      "FPS: 8.24\n",
      "\n",
      "0: 480x640 1 person, 100.2ms\n",
      "Speed: 0.9ms preprocess, 100.2ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 118 milliseconds\n",
      "FPS: 8.44\n",
      "\n",
      "0: 480x640 1 person, 99.5ms\n",
      "Speed: 1.3ms preprocess, 99.5ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 121 milliseconds\n",
      "FPS: 8.29\n",
      "\n",
      "0: 480x640 1 person, 102.7ms\n",
      "Speed: 1.2ms preprocess, 102.7ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 123 milliseconds\n",
      "FPS: 8.13\n",
      "\n",
      "0: 480x640 1 person, 110.8ms\n",
      "Speed: 1.3ms preprocess, 110.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 128 milliseconds\n",
      "FPS: 7.79\n",
      "\n",
      "0: 480x640 1 person, 101.8ms\n",
      "Speed: 0.9ms preprocess, 101.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 111 milliseconds\n",
      "FPS: 8.97\n",
      "\n",
      "0: 480x640 1 person, 102.3ms\n",
      "Speed: 1.1ms preprocess, 102.3ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 120 milliseconds\n",
      "FPS: 8.32\n",
      "\n",
      "0: 480x640 1 person, 100.8ms\n",
      "Speed: 1.4ms preprocess, 100.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 121 milliseconds\n",
      "FPS: 8.25\n",
      "\n",
      "0: 480x640 1 person, 116.9ms\n",
      "Speed: 0.9ms preprocess, 116.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 136 milliseconds\n",
      "FPS: 7.36\n",
      "\n",
      "0: 480x640 1 person, 100.2ms\n",
      "Speed: 1.6ms preprocess, 100.2ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 137 milliseconds\n",
      "FPS: 7.30\n",
      "\n",
      "0: 480x640 1 person, 104.2ms\n",
      "Speed: 1.0ms preprocess, 104.2ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 123 milliseconds\n",
      "FPS: 8.15\n",
      "\n",
      "0: 480x640 1 person, 103.4ms\n",
      "Speed: 1.2ms preprocess, 103.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 117 milliseconds\n",
      "FPS: 8.51\n",
      "\n",
      "0: 480x640 1 person, 112.5ms\n",
      "Speed: 1.6ms preprocess, 112.5ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 131 milliseconds\n",
      "FPS: 7.64\n",
      "\n",
      "0: 480x640 1 person, 102.4ms\n",
      "Speed: 0.9ms preprocess, 102.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 108 milliseconds\n",
      "FPS: 9.27\n",
      "\n",
      "0: 480x640 1 person, 99.3ms\n",
      "Speed: 0.9ms preprocess, 99.3ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 122 milliseconds\n",
      "FPS: 8.22\n",
      "\n",
      "0: 480x640 1 person, 107.5ms\n",
      "Speed: 1.0ms preprocess, 107.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 126 milliseconds\n",
      "FPS: 7.91\n",
      "\n",
      "0: 480x640 1 person, 122.7ms\n",
      "Speed: 1.1ms preprocess, 122.7ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 139 milliseconds\n",
      "FPS: 7.19\n",
      "\n",
      "0: 480x640 1 person, 100.7ms\n",
      "Speed: 1.0ms preprocess, 100.7ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Time to process 1 frame: 133 milliseconds\n",
      "FPS: 7.52\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[E thread_pool.cpp:110] Exception in thread pool task: mutex lock failed: Invalid argument\n",
      "[E thread_pool.cpp:110] Exception in thread pool task: mutex lock failed: Invalid argument\n",
      "[E thread_pool.cpp:110] Exception in thread pool task: mutex lock failed: Invalid argument\n",
      "[E thread_pool.cpp:110] Exception in thread pool task: mutex lock failed: Invalid argument\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCam Error\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m detection \u001b[38;5;241m=\u001b[39m model(frame)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m detection\u001b[38;5;241m.\u001b[39mboxes\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mtolist(): \u001b[38;5;66;03m# data : [xmin, ymin, xmax, ymax, confidence_score, class_id]\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     confidence \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(data[\u001b[38;5;241m4\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/ultralytics/engine/model.py:98\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, source, stream, **kwargs)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, source\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     97\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Calls the predict() method with given arguments to perform object detection.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 98\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(source, stream, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/ultralytics/engine/model.py:257\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prompts \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mset_prompts\u001b[39m\u001b[38;5;124m'\u001b[39m):  \u001b[38;5;66;03m# for SAM-type models\u001b[39;00m\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mset_prompts(prompts)\n\u001b[0;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mpredict_cli(source\u001b[38;5;241m=\u001b[39msource) \u001b[38;5;28;01mif\u001b[39;00m is_cli \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor(source\u001b[38;5;241m=\u001b[39msource, stream\u001b[38;5;241m=\u001b[39mstream)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/ultralytics/engine/predictor.py:198\u001b[0m, in \u001b[0;36mBasePredictor.__call__\u001b[0;34m(self, source, model, stream, *args, **kwargs)\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_inference(source, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 198\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_inference(source, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py:35\u001b[0m, in \u001b[0;36m_wrap_generator.<locals>.generator_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;66;03m# Issuing `None` to a generator fires it up\u001b[39;00m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m---> 35\u001b[0m         response \u001b[38;5;241m=\u001b[39m gen\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     38\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     39\u001b[0m             \u001b[38;5;66;03m# Forward the response to our caller and get its next request\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/ultralytics/engine/predictor.py:266\u001b[0m, in \u001b[0;36mBasePredictor.stream_inference\u001b[0;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# Inference\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m profilers[\u001b[38;5;241m1\u001b[39m]:\n\u001b[0;32m--> 266\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minference(im, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39membed:\n\u001b[1;32m    268\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m [preds] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(preds, torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;28;01melse\u001b[39;00m preds  \u001b[38;5;66;03m# yield embedding tensors\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/ultralytics/engine/predictor.py:137\u001b[0m, in \u001b[0;36mBasePredictor.inference\u001b[0;34m(self, im, *args, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Runs inference on a given image using the specified model and arguments.\"\"\"\u001b[39;00m\n\u001b[1;32m    135\u001b[0m visualize \u001b[38;5;241m=\u001b[39m increment_path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_dir \u001b[38;5;241m/\u001b[39m Path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mstem,\n\u001b[1;32m    136\u001b[0m                            mkdir\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mvisualize \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource_type\u001b[38;5;241m.\u001b[39mtensor) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(im, augment\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39maugment, visualize\u001b[38;5;241m=\u001b[39mvisualize, embed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39membed, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/ultralytics/nn/autobackend.py:356\u001b[0m, in \u001b[0;36mAutoBackend.forward\u001b[0;34m(self, im, augment, visualize, embed)\u001b[0m\n\u001b[1;32m    353\u001b[0m     im \u001b[38;5;241m=\u001b[39m im\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# torch BCHW to numpy BHWC shape(1,320,192,3)\u001b[39;00m\n\u001b[1;32m    355\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpt \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnn_module:  \u001b[38;5;66;03m# PyTorch\u001b[39;00m\n\u001b[0;32m--> 356\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(im, augment\u001b[38;5;241m=\u001b[39maugment, visualize\u001b[38;5;241m=\u001b[39mvisualize, embed\u001b[38;5;241m=\u001b[39membed)\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjit:  \u001b[38;5;66;03m# TorchScript\u001b[39;00m\n\u001b[1;32m    358\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(im)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/ultralytics/nn/tasks.py:42\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# for cases of training and validating while training.\u001b[39;00m\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 42\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/ultralytics/nn/tasks.py:60\u001b[0m, in \u001b[0;36mBaseModel.predict\u001b[0;34m(self, x, profile, visualize, augment, embed)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m augment:\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_augment(x)\n\u001b[0;32m---> 60\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_once(x, profile, visualize, embed)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/ultralytics/nn/tasks.py:81\u001b[0m, in \u001b[0;36mBaseModel._predict_once\u001b[0;34m(self, x, profile, visualize, embed)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m profile:\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_profile_one_layer(m, x, dt)\n\u001b[0;32m---> 81\u001b[0m x \u001b[38;5;241m=\u001b[39m m(x)  \u001b[38;5;66;03m# run\u001b[39;00m\n\u001b[1;32m     82\u001b[0m y\u001b[38;5;241m.\u001b[39mappend(x \u001b[38;5;28;01mif\u001b[39;00m m\u001b[38;5;241m.\u001b[39mi \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# save output\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m visualize:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/ultralytics/nn/modules/block.py:204\u001b[0m, in \u001b[0;36mC2f.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    202\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv1(x)\u001b[38;5;241m.\u001b[39mchunk(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m    203\u001b[0m y\u001b[38;5;241m.\u001b[39mextend(m(y[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm)\n\u001b[0;32m--> 204\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv2(torch\u001b[38;5;241m.\u001b[39mcat(y, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/ultralytics/nn/modules/conv.py:40\u001b[0m, in \u001b[0;36mConv.forward_fuse\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward_fuse\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     39\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Perform transposed convolution of 2D data.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv(x))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/activation.py:393\u001b[0m, in \u001b[0;36mSiLU.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 393\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39msilu(\u001b[38;5;28minput\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minplace)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/functional.py:2071\u001b[0m, in \u001b[0;36msilu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m   2069\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(silu, (\u001b[38;5;28minput\u001b[39m,), \u001b[38;5;28minput\u001b[39m, inplace\u001b[38;5;241m=\u001b[39minplace)\n\u001b[1;32m   2070\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m-> 2071\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39msilu_(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m   2072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39msilu(\u001b[38;5;28minput\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "\n",
    "while True:\n",
    "    start = datetime.datetime.now()\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print('Cam Error')\n",
    "        break\n",
    "\n",
    "    detection = model(frame)[0]\n",
    "\n",
    "    for data in detection.boxes.data.tolist(): # data : [xmin, ymin, xmax, ymax, confidence_score, class_id]\n",
    "        confidence = float(data[4])\n",
    "        if confidence < CONFIDENCE_THRESHOLD:\n",
    "            continue\n",
    "\n",
    "        xmin, ymin, xmax, ymax = int(data[0]), int(data[1]), int(data[2]), int(data[3])\n",
    "        label = int(data[5])\n",
    "        cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), GREEN, 2)\n",
    "        cv2.putText(frame, class_list[label]+' '+str(round(confidence, 2)) + '%', (xmin, ymin), cv2.FONT_ITALIC, 1, WHITE, 2)\n",
    "\n",
    "    end = datetime.datetime.now()\n",
    "\n",
    "    total = (end - start).total_seconds()\n",
    "    print(f'Time to process 1 frame: {total * 1000:.0f} milliseconds')\n",
    "\n",
    "    fps = f'FPS: {1 / total:.2f}'\n",
    "    cv2.putText(frame, fps, (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "    print(f'FPS: {1 / total:.2f}')\n",
    "\n",
    "    cv2.imshow('frame', frame)\n",
    "\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c15c138",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
